{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb94886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "\n",
    "from data_utils import prep_data\n",
    "from model import EncoderRNN, LuongAttnDecoderRNN, GreedySearchDecoder, loss_function\n",
    "from global_hparams import voc_hparams, data_hparams\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "\n",
    "from torch import optim\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b75051c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_name = 'data'\n",
    "corpus = os.path.join(corpus_name)\n",
    "filename = \"formatted_movie_lines.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ad61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = os.path.join(corpus, filename)\n",
    "\n",
    "delimiter = str(codecs.decode('\\n', \"unicode_escape\"))\n",
    "\n",
    "# Initialize lines dict, conversations list, and field ids\n",
    "lines = {}\n",
    "conversations = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de714d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 442564 sentence pairs\n",
      "Trimmed to 428758 sentence pairs\n",
      "Counting words...\n",
      "['canwemakethisquick?roxannekorrineandandrewbarrettarehavinganincrediblyhorrendouspublicbreakuponthequad.again.', 'can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .']\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "prep_data_obj = prep_data(data_hparams['MAX_LENGTH'])\n",
    "voc, pairs = prep_data_obj.loadPrepareData(corpus, corpus_name, datafile, save_dir)\n",
    "for pair in pairs[:1]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f18a2600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count all the characters\n",
    "all_c = sum(list(voc.word2count.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48694e0d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'PAD',\n",
       " 1: 'SOS',\n",
       " 2: 'EOS',\n",
       " 3: 'c',\n",
       " 4: 'a',\n",
       " 5: 'n',\n",
       " 6: ' ',\n",
       " 7: 'w',\n",
       " 8: 'e',\n",
       " 9: 'm',\n",
       " 10: 'k',\n",
       " 11: 't',\n",
       " 12: 'h',\n",
       " 13: 'i',\n",
       " 14: 's',\n",
       " 15: 'q',\n",
       " 16: 'u',\n",
       " 17: '?',\n",
       " 18: 'r',\n",
       " 19: 'o',\n",
       " 20: 'x',\n",
       " 21: 'd',\n",
       " 22: 'b',\n",
       " 23: 'v',\n",
       " 24: 'g',\n",
       " 25: 'l',\n",
       " 26: 'y',\n",
       " 27: 'p',\n",
       " 28: '.',\n",
       " 29: 'f',\n",
       " 30: 'j',\n",
       " 31: 'z',\n",
       " 32: '!'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef4ed26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2160765254803255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count only spaces\n",
    "voc.word2count[' ']/all_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f86b8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "train_pairs = pairs[:int(len(pairs)*train_ratio)]\n",
    "test_pairs = pairs[int(len(pairs)*train_ratio):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c4cb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: torch.Size([126, 50])\n",
      "lengths: tensor([126, 119, 112, 109,  96,  89,  88,  69,  57,  50,  49,  48,  43,  41,\n",
      "         39,  38,  34,  32,  32,  31,  31,  31,  29,  21,  21,  21,  20,  20,\n",
      "         19,  19,  18,  18,  18,  18,  18,  18,  16,  15,  14,  12,  11,   9,\n",
      "          9,   6,   6,   6,   5,   5,   5,   4])\n",
      "target_variable: tensor([[19, 25,  4,  ..., 26,  7,  5],\n",
      "        [12, 13,  5,  ...,  8, 12, 19],\n",
      "        [ 6, 14, 21,  ..., 14, 26,  6],\n",
      "        ...,\n",
      "        [ 6,  0,  0,  ...,  0,  0,  0],\n",
      "        [32,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 2,  0,  0,  ...,  0,  0,  0]])\n",
      "mask: tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [ True, False, False,  ..., False, False, False],\n",
      "        [ True, False, False,  ..., False, False, False],\n",
      "        [ True, False, False,  ..., False, False, False]])\n",
      "max_target_len: 165\n"
     ]
    }
   ],
   "source": [
    "# Example for validation\n",
    "small_batch_size = 50\n",
    "batches = prep_data_obj.batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable.shape)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5050baf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19, 12, 26,  8, 14, 13, 21, 19, 30, 19,  8, 28, 22,  8, 25, 13,  8, 23,\n",
       "         8,  9,  8, 28, 26, 19, 16, 14,  4, 26, 26, 19, 16, 18,  8, 24, 19, 13,\n",
       "         5, 24, 11, 19, 25, 19, 14,  8, 28, 13, 14, 13, 11,  9, 26, 29,  4, 16,\n",
       "        25, 11, 17, 25, 13, 14, 11,  8,  5, 32, 11, 12,  8, 21,  4,  9,  5,  8,\n",
       "        21,  3,  4, 14,  8, 21, 19,  8, 14,  5, 11, 14, 11,  4, 18, 11, 16,  5,\n",
       "        11, 13, 25, 11, 19,  9, 19, 18, 18, 19,  7,  4,  5, 21,  4, 25, 18,  8,\n",
       "         4, 21, 26, 13, 11, 14, 19, 23,  8, 18, 29, 19, 18, 26, 19, 16, 32,  2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Input to the model\n",
    "input_variable[:,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73d211ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19, 12,  6, 26,  8, 14,  6, 13,  6, 21, 19,  6, 30, 19,  8,  6, 28,  6,\n",
       "        22,  8, 25, 13,  8, 23,  8,  6,  9,  8,  6, 28,  6, 26, 19, 16,  6, 14,\n",
       "         4, 26,  6, 26, 19, 16,  6, 18,  8,  6, 24, 19, 13,  5, 24,  6, 11, 19,\n",
       "         6, 25, 19, 14,  8,  6, 28,  6, 13, 14,  6, 13, 11,  6,  9, 26,  6, 29,\n",
       "         4, 16, 25, 11,  6, 17,  6, 25, 13, 14, 11,  8,  5,  6, 32,  6, 11, 12,\n",
       "         8,  6, 21,  4,  9,  5,  8, 21,  6,  3,  4, 14,  8,  6, 21, 19,  8, 14,\n",
       "         5,  6, 11,  6, 14, 11,  4, 18, 11,  6, 16,  5, 11, 13, 25,  6, 11, 19,\n",
       "         9, 19, 18, 18, 19,  7,  6,  4,  5, 21,  6,  4, 25, 18,  8,  4, 21, 26,\n",
       "         6, 13, 11,  6, 14,  6, 19, 23,  8, 18,  6, 29, 19, 18,  6, 26, 19, 16,\n",
       "         6, 32,  2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected output from the model\n",
    "target_variable[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787fac76",
   "metadata": {},
   "source": [
    "###  Input sentence and expected output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef6df4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ohyesidojoe.believeme.yousayyouregoingtolose.isitmyfault?listen!thedamnedcasedoesntstartuntiltomorrowandalreadyitsoverforyou!EOS'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input sentence\n",
    "''.join([voc.index2word[i.item()] for i in input_variable[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf941a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh yes i do joe . believe me . you say you re going to lose . is it my fault ? listen ! the damned case doesn t start until tomorrow and already it s over for you !EOS'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output sentence\n",
    "''.join([voc.index2word[i.item()] for i in target_variable[:,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2885810",
   "metadata": {},
   "source": [
    "### Lets built the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "821e9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          loss_fns, encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=data_hparams['MAX_LENGTH']):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "    # Lengths for rnn packing should always be on the cpu\n",
    "    lengths = lengths.to(\"cpu\")\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[voc_hparams['SOS_token'] for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = loss_fns.maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = loss_fns.maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "334560de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, loss_fn ,encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [prep_data_obj.batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    print(f\"total training batches that you will need are {len(pairs)//batch_size}\")\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, loss_fn, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f95018e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=data_hparams['MAX_LENGTH']):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [prep_data_obj.indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    #lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = prep_data_obj.normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Model Output:', ''.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d20acca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot' #  'general' or 'concat'\n",
    "hidden_size = 512\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "checkpoint_iter = 200\n",
    "#loadFilename = None\n",
    "loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "                        '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "                        '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "loss_fn = loss_function(device)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a977e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 200\n",
    "print_every = 10\n",
    "save_every = 50\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# If you have cuda, configure cuda to call\n",
    "for state in encoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "\n",
    "for state in decoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "            \n",
    "# Run training iterations\n",
    "print(\"Training is started!\")\n",
    "trainIters(model_name, voc, train_pairs, encoder, decoder, loss_fn , encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f95488",
   "metadata": {},
   "source": [
    "### Test sentences from same domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "678991a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [i[0] for i in test_pairs[:30] if len(i[0]) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef206c13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "searcher = GreedySearchDecoder(encoder, decoder, device)\n",
    "try:\n",
    "    outputs = []\n",
    "    for input_sentence in test_sentences:\n",
    "        input_sentence = prep_data_obj.normalizeString(input_sentence+'..')\n",
    "        output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "        output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "        outputs.append([input_sentence, ''.join(output_words).split('. . .')[0]])\n",
    "        \n",
    "except KeyError:\n",
    "    print(\"Error: Encountered unknown character.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64acb6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['yourwifeandchildrenarebackinnewhampshireinthesnow ? . .',\n",
       "  'your wife and children are back in new hampshire in the s now ? . ? ! '],\n",
       " ['yourwifeandchildrenarebackinnewhampshireinthesnow ? . .',\n",
       "  'your wife and children are back in new hampshire in the s now ? . ? ! '],\n",
       " ['yeahtheyreinthesnow . . .', 'yeah they re in the s now '],\n",
       " ['aretheypolarbearstoo ? . .', 'are they polar bears too ? '],\n",
       " ['goodgodthewayyoulivehere .thisplacehasntbeendustedsincemotherdied .lookatthatgoddamnedrefrigerator . . .',\n",
       "  'good god the way you live here . this place hasn t been dusted since mother died . look at that goddamned refrigerator '],\n",
       " ['goodgodthewayyoulivehere .thisplacehasntbeendustedsincemotherdied .lookatthatgoddamnedrefrigerator . . .',\n",
       "  'good god the way you live here . this place hasn t been dusted since mother died . look at that goddamned refrigerator '],\n",
       " ['gotanothertwentyyearsinitboy .bythewaysondoyourecallrosethatprettyblondegirlwhocametoourhousewaybackinorandcausedsuchadamnablecommotion . . .',\n",
       "  'got a nother twenty years in it boy . by the ways on do you recall rose that pretty blondegirl who came to our house way back in or and caused such adamn able commotion '],\n",
       " ['gotanothertwentyyearsinitboy .bythewaysondoyourecallrosethatprettyblondegirlwhocametoourhousewaybackinorandcausedsuchadamnablecommotion . . .',\n",
       "  'got a nother twenty years in it boy . by the ways on do you recall rose that pretty blondegirl who came to our house way back in or and caused such adamn able commotion '],\n",
       " ['ofcourseirecallrose .infactivebeenthinkingofnooneelseforthelasthourandahalf . . .',\n",
       "  'of course i recall rose . in factive been thinking of no one else for the last hour and alf '],\n",
       " ['ofcourseirecallrose .infactivebeenthinkingofnooneelseforthelasthourandahalf . . .',\n",
       "  'of course i recall rose . in factive been thinking of no one else for the last hour and alf ']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[5:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ec0d3",
   "metadata": {},
   "source": [
    "### Lets test model with some random sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "288e9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = [\"thismodelputspacesbetweencharacters\",\n",
    "              \"ithinkicansolvethisriddle\",\n",
    "              'wellyouareamazing',\n",
    "              'adogisverypissedatme!',\n",
    "              'ithinkilovethismovie.charactersfromthismotionpictureisawesome',\n",
    "              'thisisabeautifulcap',\n",
    "              'icansolvethispuzzleveryeasily',\n",
    "              'usuallyachairhasfourlegs',\n",
    "              'tablealsohasfourlegs',\n",
    "              'thisismysignature.',\n",
    "              'knowledgeisnotsameaswisdom.',\n",
    "              \"iamsorryidontwanttosoundrudesbutareyouplanningtodothisactivity?\"\n",
    "             ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7ab2ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    outputs = []\n",
    "    for input_sentence in test_input:\n",
    "        input_sentence = prep_data_obj.normalizeString(input_sentence+'..')\n",
    "        output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "        output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "        outputs.append([input_sentence, ''.join(output_words).split('. . .')[0]])\n",
    "        \n",
    "except KeyError:\n",
    "    print(\"Error: Encountered unknown character.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e1fc67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['thismodelputspacesbetweencharacters . .',\n",
       "  'this model put spaces between characters '],\n",
       " ['ithinkicansolvethisriddle . .', 'i think i can solvethis riddle '],\n",
       " ['wellyouareamazing . .', 'well you are a mazing '],\n",
       " ['adogisverypissedatme ! . .', 'a dog is very pissed at me ! ! '],\n",
       " ['ithinkilovethismovie .charactersfromthismotionpictureisawesome . .',\n",
       "  'i think i love this movie . characters from this motion picture is a we some '],\n",
       " ['thisisabeautifulcap . .', 'this is a beautiful cap '],\n",
       " ['icansolvethispuzzleveryeasily . .', 'i can solvethis puzzle very easily '],\n",
       " ['usuallyachairhasfourlegs . .', 'usually a chair has four legs '],\n",
       " ['tablealsohasfourlegs . .', 'table also has four legs '],\n",
       " ['thisismysignature . . .', 'this is mysignature '],\n",
       " ['knowledgeisnotsameaswisdom . . .', 'know ledge is not same as wisdom '],\n",
       " ['iamsorryidontwanttosoundrudesbutareyouplanningtodothisactivity ? . .',\n",
       "  'i am sorry i don t want to sound rudes but are you planning to do this activity ? . ? ']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89287bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
