{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb94886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from data_utils import prep_data\n",
    "from model import EncoderRNN, LuongAttnDecoderRNN, GreedySearchDecoder, loss_function\n",
    "from global_hparams import voc_hparams, data_hparams\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b75051c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_name = 'data'\n",
    "corpus = os.path.join(corpus_name)\n",
    "filename = \"formatted_movie_lines.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ad61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = os.path.join(corpus, filename)\n",
    "\n",
    "delimiter = str(codecs.decode('\\n', \"unicode_escape\"))\n",
    "\n",
    "# Initialize lines dict, conversations list, and field ids\n",
    "lines = {}\n",
    "conversations = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de714d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 442564 sentence pairs\n",
      "Trimmed to 428758 sentence pairs\n",
      "Counting words...\n",
      "['canwemakethisquick?roxannekorrineandandrewbarrettarehavinganincrediblyhorrendouspublicbreakuponthequad.again.', 'can we make this quick ? roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad . again .']\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "prep_data_obj = prep_data(data_hparams['MAX_LENGTH'])\n",
    "voc, pairs = prep_data_obj.loadPrepareData(corpus, corpus_name, datafile, save_dir)\n",
    "for pair in pairs[:1]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f18a2600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count all the characters\n",
    "all_c = sum(list(voc.word2count.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48694e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'PAD',\n",
       " 1: 'SOS',\n",
       " 2: 'EOS',\n",
       " 3: 'c',\n",
       " 4: 'a',\n",
       " 5: 'n',\n",
       " 6: ' ',\n",
       " 7: 'w',\n",
       " 8: 'e',\n",
       " 9: 'm',\n",
       " 10: 'k',\n",
       " 11: 't',\n",
       " 12: 'h',\n",
       " 13: 'i',\n",
       " 14: 's',\n",
       " 15: 'q',\n",
       " 16: 'u',\n",
       " 17: '?',\n",
       " 18: 'r',\n",
       " 19: 'o',\n",
       " 20: 'x',\n",
       " 21: 'd',\n",
       " 22: 'b',\n",
       " 23: 'v',\n",
       " 24: 'g',\n",
       " 25: 'l',\n",
       " 26: 'y',\n",
       " 27: 'p',\n",
       " 28: '.',\n",
       " 29: 'f',\n",
       " 30: 'j',\n",
       " 31: 'z',\n",
       " 32: '!'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef4ed26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2160765254803255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.word2count[' ']/all_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f86b8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "train_pairs = pairs[:int(len(pairs)*train_ratio)]\n",
    "test_pairs = pairs[int(len(pairs)*train_ratio):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c4cb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: torch.Size([154, 50])\n",
      "lengths: tensor([154, 134, 119, 107, 105,  93,  91,  80,  77,  75,  55,  52,  38,  32,\n",
      "         32,  28,  28,  28,  26,  26,  26,  26,  26,  26,  25,  25,  23,  22,\n",
      "         21,  20,  20,  18,  17,  17,  16,  14,  14,  12,  12,  12,  11,  11,\n",
      "         11,  10,  10,   8,   6,   5,   5,   5])\n",
      "target_variable: tensor([[26,  4, 26,  ..., 26,  7, 26],\n",
      "        [19,  5,  8,  ...,  8, 12,  8],\n",
      "        [16, 21,  4,  ..., 14, 26, 14],\n",
      "        ...,\n",
      "        [ 9,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 8,  0,  0,  ...,  0,  0,  0],\n",
      "        [ 2,  0,  0,  ...,  0,  0,  0]])\n",
      "mask: tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [ True, False, False,  ..., False, False, False],\n",
      "        [ True, False, False,  ..., False, False, False],\n",
      "        [ True, False, False,  ..., False, False, False]])\n",
      "max_target_len: 198\n"
     ]
    }
   ],
   "source": [
    "# Example for validation\n",
    "small_batch_size = 50\n",
    "batches = prep_data_obj.batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable.shape)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5050baf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26, 19, 16, 21, 19,  5, 11,  7, 18,  8, 14, 11, 25,  8, 13, 29, 26, 19,\n",
       "        16, 21, 19,  5, 11, 12,  4, 23,  8, 14, 16, 27, 18,  8,  9,  8,  3, 19,\n",
       "         5, 29, 13, 21,  8,  5,  3,  8,  4,  5, 21, 13,  7, 18,  8, 14, 11, 25,\n",
       "         8, 21, 28, 22, 16, 11,  7, 12,  8,  5, 13, 24,  8, 11,  7, 13, 11, 12,\n",
       "        26, 19, 16,  4,  5, 21, 13, 14,  4, 26, 11, 19,  9, 26, 14,  8, 25, 29,\n",
       "         9, 26, 24, 19, 21, 12,  8, 18,  8, 13,  4,  9,  7, 13, 11, 12, 11, 12,\n",
       "         8,  7, 13, 29,  8, 19, 29, 12,  4, 18, 19, 25, 21, 18, 26,  4,  5, 19,\n",
       "         5,  8, 19, 29, 11, 12,  8, 24, 18,  8,  4, 11, 12,  8, 18, 19,  8, 14,\n",
       "        19, 29,  4, 25, 25, 11, 13,  9,  8,  2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_variable[:,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73d211ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26, 19, 16,  6, 21, 19,  5,  6, 11,  6,  7, 18,  8, 14, 11, 25,  8,  6,\n",
       "        13, 29,  6, 26, 19, 16,  6, 21, 19,  5,  6, 11,  6, 12,  4, 23,  8,  6,\n",
       "        14, 16, 27, 18,  8,  9,  8,  6,  3, 19,  5, 29, 13, 21,  8,  5,  3,  8,\n",
       "         6,  4,  5, 21,  6, 13,  6,  7, 18,  8, 14, 11, 25,  8, 21,  6, 28,  6,\n",
       "        22, 16, 11,  6,  7, 12,  8,  5,  6, 13,  6, 24,  8, 11,  6,  7, 13, 11,\n",
       "        12,  6, 26, 19, 16,  6,  4,  5, 21,  6, 13,  6, 14,  4, 26,  6, 11, 19,\n",
       "         6,  9, 26, 14,  8, 25, 29,  6,  9, 26,  6, 24, 19, 21,  6, 12,  8, 18,\n",
       "         8,  6, 13,  6,  4,  9,  6,  7, 13, 11, 12,  6, 11, 12,  8,  6,  7, 13,\n",
       "        29,  8,  6, 19, 29,  6, 12,  4, 18, 19, 25, 21,  6, 18, 26,  4,  5,  6,\n",
       "        19,  5,  8,  6, 19, 29,  6, 11, 12,  8,  6, 24, 18,  8,  4, 11,  6, 12,\n",
       "         8, 18, 19,  8, 14,  6, 19, 29,  6,  4, 25, 25,  6, 11, 13,  9,  8,  2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_variable[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef6df4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youdontwrestleifyoudonthavesupremeconfidenceandiwrestled.butwhenigetwithyouandisaytomyselfmygodhereiamwiththewifeofharoldryanoneofthegreatheroesofalltimeEOS'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input sentence\n",
    "''.join([voc.index2word[i.item()] for i in input_variable[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf941a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you don t wrestle if you don t have supreme confidence and i wrestled . but when i get with you and i say to myself my god here i am with the wife of harold ryan one of the great heroes of all timeEOS'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output sentence\n",
    "''.join([voc.index2word[i.item()] for i in target_variable[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "821e9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          loss_fns, encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=data_hparams['MAX_LENGTH']):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "    # Lengths for rnn packing should always be on the cpu\n",
    "    lengths = lengths.to(\"cpu\")\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[voc_hparams['SOS_token'] for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = loss_fns.maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = loss_fns.maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "334560de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, loss_fn ,encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [prep_data_obj.batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    print(f\"total training batches that you will need are {len(pairs)//batch_size}\")\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, loss_fn, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f95018e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=data_hparams['MAX_LENGTH']):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [prep_data_obj.indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    #lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = prep_data_obj.normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Model Output:', ''.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d20acca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot' #  'general' or 'concat'\n",
    "hidden_size = 512\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "#checkpoint_iter = 200\n",
    "loadFilename = None\n",
    "# loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "loss_fn = loss_function(device)\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a977e038",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Training is started!\n",
      "Initializing ...\n",
      "total training batches that you will need are 5359\n",
      "Training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7d975fac310d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m trainIters(model_name, voc, train_pairs, encoder, decoder, loss_fn , encoder_optimizer, decoder_optimizer,\n\u001b[1;32m     36\u001b[0m            \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_n_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_n_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m            print_every, save_every, clip, corpus_name, loadFilename)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-caf04f85bcd4>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(model_name, voc, pairs, encoder, decoder, loss_fn, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Run a training iteration with batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n\u001b[0;32m---> 24\u001b[0;31m                      decoder, embedding, loss_fn, encoder_optimizer, decoder_optimizer, batch_size, clip)\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mprint_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-1deb9cdeb327>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, loss_fns, encoder_optimizer, decoder_optimizer, batch_size, clip, max_length)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# Perform backpropatation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Clip gradients: gradients are modified in place\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 200\n",
    "print_every = 10\n",
    "save_every = 50\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# If you have cuda, configure cuda to call\n",
    "for state in encoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "\n",
    "for state in decoder_optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.cuda()\n",
    "            \n",
    "# Run training iterations\n",
    "print(\"Training is started!\")\n",
    "trainIters(model_name, voc, train_pairs, encoder, decoder, loss_fn , encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "678991a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [i[0] for i in test_pairs[:30] if len(i[0]) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef206c13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "searcher = GreedySearchDecoder(encoder, decoder, device)\n",
    "try:\n",
    "    outputs = []\n",
    "    for input_sentence in test_sentences:\n",
    "        input_sentence = prep_data_obj.normalizeString(input_sentence)\n",
    "        output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "        output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "        outputs.append([input_sentence, ''.join(output_words)])\n",
    "        \n",
    "except KeyError:\n",
    "    print(\"Error: Encountered unknown character.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64acb6a8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aboutasgoodascanbeexpectedwithonefootinthegrave .goodtoseeyouson .didyoubringanyofthatyankeewhiskywithyou ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['itisntyankeewhiskydaddyitsscotch .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['itisntyankeewhiskydaddyitsscotch .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['itsyankeewhiskytome .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['icanuseadrinkaftertheplanerideihad .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['yourwifeandchildrenarebackinnewhampshireinthesnow ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['yourwifeandchildrenarebackinnewhampshireinthesnow ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['yeahtheyreinthesnow .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['aretheypolarbearstoo ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['goodgodthewayyoulivehere .thisplacehasntbeendustedsincemotherdied .lookatthatgoddamnedrefrigerator .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['goodgodthewayyoulivehere .thisplacehasntbeendustedsincemotherdied .lookatthatgoddamnedrefrigerator .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['gotanothertwentyyearsinitboy .bythewaysondoyourecallrosethatprettyblondegirlwhocametoourhousewaybackinorandcausedsuchadamnablecommotion .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['gotanothertwentyyearsinitboy .bythewaysondoyourecallrosethatprettyblondegirlwhocametoourhousewaybackinorandcausedsuchadamnablecommotion .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['ofcourseirecallrose .infactivebeenthinkingofnooneelseforthelasthourandahalf .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['ofcourseirecallrose .infactivebeenthinkingofnooneelseforthelasthourandahalf .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['howcouldthatbeson ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['howcouldthatbeson ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['davewilkieofallpeoplewassittingbymeontheplaneherfirsthusband .itsfunnyyouwouldmentionrose .didyouhearfromher ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['whatsallthisaboutrose ?whatdoyoumeanyouheardfromherinamannerofspeaking ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['ohiheardfromherigotaletterfromhershesfine .butthereissomesadnews .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['ohiheardfromherigotaletterfromhershesfine .butthereissomesadnews .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['whatsadnews ?didhercancercomeback ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['whatsadnews ?didhercancercomeback ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['ohnonoshegotalloverthat .roseisfine .letssitdownson .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['ohnonoshegotalloverthat .roseisfine .letssitdownson .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['isherhusbandsickorsomething ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['isherhusbandsickorsomething ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['noitsanotherthing .iwasgoingtowriteyouaboutitbutsinceyouwerecomingdownanywayithoughtidwaittillyougothere .whatdiddavewilkiehavetosay ?',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['thepitifulsonofabitchsaidrosewasanymphomaniac .',\n",
       "  '                                                                                                                                                                                                        '],\n",
       " ['umhmmandisupposethatincensedyou ?',\n",
       "  '                                                                                                                                                                                                        ']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_input = [\"thismodelputspacesbetweencharacters\",\n",
    "#               \"ithinkicansolvethisriddle\",\n",
    "#               'wellyouareamazing',\n",
    "#               'adogisverypissedatme!',\n",
    "#               'ithinkilovethismovie.charactersfromthismotionpictureisawesome',\n",
    "#               'thisisabeautifulcap',\n",
    "#               'icansolvethispuzzleveryeasily',\n",
    "#               'usuallyachairhasfourlegs',\n",
    "#               'tablealsohasfourlegs',\n",
    "#               'thisismysignature.',\n",
    "#               'knowlegeisnotsameaswisdom.',\n",
    "#               \"iamsorryidon'twanttoosoundrudesbutareyouplanningtodothisactivity?\"\n",
    "#               'themorningsunlightgivesyoumorevitamindthantablets'\n",
    "#              ] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
